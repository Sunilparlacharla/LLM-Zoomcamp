{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ec4e9a-074b-4449-a9b9-adec8aa8f0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-22 11:33:25--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-06-22 11:33:25 (18.2 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69492646-518c-438a-ab40-1509afbfe70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31311bad-e21e-4ee3-9c66-b32b42b8823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006c91e0-2a61-4b80-a8b7-6ad9c69695ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b87ca8-4eb6-4ac8-94b4-a3280f389dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb99503d-1d1e-4474-9922-6f7f6bc8356b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "463c8f66-ff90-4b82-a986-48d63fb21cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da17520-1fc9-4397-945f-e434ba41ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SELECT * WHERE course = 'data-engineering-zoomcamp';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba539609-bb60-4f88-a002-9abb08ef2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2244d167-ca24-49ea-b90b-20445af4d562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f6285082650>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc9b1853-51dc-42eb-8ef9-00ef8517baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ec8ade-3097-494e-a3fd-56fdcd4cc395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\",\n",
       "  'section': 'Workshop 1 - dlthub',\n",
       "  'question': 'How do I install the necessary dependencies to run the code?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: ./build.sh: Permission denied Error',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead',\n",
       "  'section': 'Project',\n",
       "  'question': 'How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'how do I run kafka?'\n",
    "search_results = search(query)\n",
    "\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "825e50aa-3a42-4915-8125-0cbc64b8d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c88dee2-4c8a-49a7-9603-11b70ccf2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(query, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b153f88-1349-4af1-b3c5-5157aeede0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\n    Use only the facts from the CONTEXT when answering the QUESTION.\\n    \\n    QUESTION: how do I run kafka?\\n    \\n    CONTEXT: \\n    section: Module 6: streaming with kafka\\nquestion: Module “kafka” not found when trying to run producer.py\\nanswer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you\\'ll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it\\'s env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\\n\\nsection: Module 6: streaming with kafka\\nquestion: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\\nanswer: In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n\\nsection: Workshop 1 - dlthub\\nquestion: How do I install the necessary dependencies to run the code?\\nanswer: Answer: To run the provided code, ensure that the \\'dlt[duckdb]\\' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\\n\\nsection: Module 6: streaming with kafka\\nquestion: Python Kafka: ./build.sh: Permission denied Error\\nanswer: Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh\\n\\nsection: Project\\nquestion: How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?\\nanswer: According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75a233dc-067d-4d19-938e-4b26609447a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "client = MistralClient()\n",
    "\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat(\n",
    "        model='open-mistral-7b',\n",
    "        messages=[\n",
    "            ChatMessage(role=\"user\", content=prompt)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e23b2a1-6b6c-48ac-bfe2-10433df024f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98dfe82c-93e9-49ba-8cbe-002fce5600e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To run Kafka in the context of the provided course, follow these steps:\\n\\n1. Create a virtual environment and install the required packages.\\n   - Run `python -m venv env` to create a virtual environment.\\n   - Activate the virtual environment using `source env/bin/activate` (on MacOS, Linux) or `env\\\\Scripts\\\\activate` (on Windows).\\n   - Install the required packages by running `pip install -r ../requirements.txt`.\\n\\n2. Install the necessary dependencies for the code.\\n   - If you're working with Python, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing `!pip install dlt[duckdb]`.\\n\\n3. Run the provided Python scripts.\\n   - For example, to run a Kafka producer, navigate to the directory containing the script and run it using `python <script_name>.py`.\\n\\n4. If you encounter a permission error while running the build script (`.sh` files), use the command `chmod +x build.sh` to grant execution permissions.\\n\\n5. For Java-based Kafka applications, navigate to the project directory and run the Java class using the command `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java`.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71b2e5cc-5dfc-429e-ac44-526f4d1dc093",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'the course has already started, can I still enroll?'\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99a5044f-a930-456a-90c2-22175b7efd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, it is stated that even if you don't register for the course after the start date, you are still eligible to submit the homeworks. However, you should be aware of the deadlines for turning in the final projects to avoid leaving everything for the last minute.\\n\\nIf you miss the start date, you won't be able to participate in the live sessions, but you can still follow the course materials after it finishes. The course materials will be kept available, and you can work on your final capstone project at your own pace.\\n\\nBefore the course starts, you can prepare by installing and setting up all the dependencies and requirements, such as a Google cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. You can also look over the prerequisites and syllabus to see if you are comfortable with these subjects.\\n\\nFor support, it is mentioned that the slack channel remains open, and you can ask questions there. It is also suggested to search the channel and the FAQ document before asking questions, and you can tag the bot @ZoomcampQABot to help you conduct the search.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8795c1-a3c5-4419-a681-f1e7e8148536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
